nohup: ignoring input
[2025-03-14 15:48:25 +0000] [8163] [INFO] Starting gunicorn 23.0.0
[2025-03-14 15:48:25 +0000] [8163] [INFO] Listening at: http://0.0.0.0:8000 (8163)
[2025-03-14 15:48:25 +0000] [8163] [INFO] Using worker: sync
[2025-03-14 15:48:25 +0000] [8164] [INFO] Booting worker with pid: 8164
2025-03-14 15:48:25.883577: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2025-03-14 15:48:25.887867: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2025-03-14 15:48:25.899539: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741967305.917865    8164 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741967305.923784    8164 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-03-14 15:48:25.943147: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
2025-03-14 15:48:28,692 - INFO - Loading trained models...
2025-03-14 15:48:28.698390: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
2025-03-14 15:48:28,987 - INFO - Intent model loaded successfully..<class 'keras.src.models.sequential.Sequential'>
2025-03-14 15:48:29,211 - INFO - Transfomer model loaded successfully..<class 'keras.src.models.functional.Functional'>
2025-03-14 15:48:29,211 - INFO - Loading tokenizers...
2025-03-14 15:48:29,211 - INFO - Intent tokenizer loaded successfully.
2025-03-14 15:48:29,366 - INFO - Transformer tokenizer loaded successfully
2025-03-14 15:48:29,366 - INFO - Loading Label Encoder...
2025-03-14 15:48:29,366 - INFO - Label Encoder loaded successfully.
2025-03-14 15:48:29,366 - INFO - Loading max sequence length...
2025-03-14 15:48:29,366 - INFO - Max sequence length: 7
2025-03-14 15:48:29,366 - INFO - Loading responses...
2025-03-14 15:48:29,366 - INFO - Responses loaded successfully.
2025-03-14 15:48:29,488 - INFO - Loading intent data...
2025-03-14 15:48:29,488 - INFO - Loading complete.
2025-03-14 15:48:29,490 - INFO - Running in production...
2025-03-14 15:48:47,050 - INFO - Processing input...
2025-03-14 15:48:47,051 - INFO - Predicting intent...
True
{'status': 'success', 'last_training_date': '11-03-2025 04:13:39', 'last_epoch_count': 100, 'total_epochs': 790, 'model_accuracy': '99.1304%', 'model_loss': '1.2730%', 'last_transformer_epochs': 10, 'total_transformer_epochs': 30, 'transformer_accuracy': 0, 'transformer_loss': 0}
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 1s/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 1s/step
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 19ms/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 31ms/step
2025-03-14 15:48:48,437 - INFO - Predicted intent: jokes (Confidence: 0.15)
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 145ms/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 158ms/step
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 128ms/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 141ms/step
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 21ms/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 33ms/step
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 17ms/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 29ms/step
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 16ms/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 29ms/step
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 18ms/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 30ms/step
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 19ms/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 33ms/step
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 18ms/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 31ms/step
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 17ms/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 31ms/step
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 16ms/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 28ms/step
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 17ms/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 29ms/step
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 15ms/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 27ms/step
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 20ms/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 33ms/step
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 18ms/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 31ms/step
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 16ms/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 30ms/step
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 19ms/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 31ms/step
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 17ms/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 30ms/step
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 18ms/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 30ms/step
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 17ms/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 29ms/step
[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 19ms/step[1m1/1[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 32ms/step
2025-03-14 15:48:50,290 - INFO - Response: you what <OOV> <OOV> you a the a the a a the a i you the a a
2025-03-14 15:48:50,290 - INFO - Checking training date...
2025-03-14 15:48:50,290 - INFO - Check complete.
True
{'status': 'success', 'last_training_date': '11-03-2025 04:13:39', 'last_epoch_count': 100, 'total_epochs': 790, 'model_accuracy': '99.1304%', 'model_loss': '1.2730%', 'last_transformer_epochs': 10, 'total_transformer_epochs': 30, 'transformer_accuracy': 0, 'transformer_loss': 0}
Epoch 1/10
[1m   1/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m4:43:02[0m 2s/step - accuracy: 0.0000e+00 - loss: 8.5641[1m   2/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:01[0m 156ms/step - accuracy: 0.0863 - loss: 8.3956   [1m   3/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m17:56[0m 155ms/step - accuracy: 0.1463 - loss: 8.2559[1m   4/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m17:56[0m 156ms/step - accuracy: 0.2016 - loss: 8.1221[1m   5/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m17:49[0m 154ms/step - accuracy: 0.2447 - loss: 8.0065[1m   6/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m17:45[0m 154ms/step - accuracy: 0.2783 - loss: 7.9105[1m   7/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m17:43[0m 154ms/step - accuracy: 0.3063 - loss: 7.8223[1m   8/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m17:43[0m 154ms/step - accuracy: 0.3283 - loss: 7.7447[1m   9/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m17:56[0m 156ms/step - accuracy: 0.3464 - loss: 7.6732[1m  10/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:21[0m 159ms/step - accuracy: 0.3614 - loss: 7.6065[1m  11/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:17[0m 159ms/step - accuracy: 0.3742 - loss: 7.5430[1m  12/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:11[0m 158ms/step - accuracy: 0.3849 - loss: 7.4837[1m  13/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:16[0m 159ms/step - accuracy: 0.3945 - loss: 7.4252[1m  14/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:18[0m 159ms/step - accuracy: 0.4029 - loss: 7.3686[1m  15/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:35[0m 161ms/step - accuracy: 0.4107 - loss: 7.3127[1m  16/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:47[0m 163ms/step - accuracy: 0.4177 - loss: 7.2579[1m  17/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:48[0m 163ms/step - accuracy: 0.4240 - loss: 7.2045[1m  18/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:21[0m 168ms/step - accuracy: 0.4300 - loss: 7.1511[1m  19/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:36[0m 170ms/step - accuracy: 0.4355 - loss: 7.0988[1m  20/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:33[0m 170ms/step - accuracy: 0.4405 - loss: 7.0474[1m  21/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:33[0m 170ms/step - accuracy: 0.4448 - loss: 6.9985[1m  22/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:28[0m 169ms/step - accuracy: 0.4489 - loss: 6.9502[1m  23/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:34[0m 170ms/step - accuracy: 0.4526 - loss: 6.9028[1m  24/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:31[0m 170ms/step - accuracy: 0.4560 - loss: 6.8568[1m  25/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:24[0m 169ms/step - accuracy: 0.4590 - loss: 6.8121[1m  26/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:21[0m 168ms/step - accuracy: 0.4618 - loss: 6.7684[1m  27/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:26[0m 169ms/step - accuracy: 0.4644 - loss: 6.7252[1m  28/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:22[0m 168ms/step - accuracy: 0.4668 - loss: 6.6828[1m  29/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:17[0m 168ms/step - accuracy: 0.4691 - loss: 6.6410[1m  30/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:14[0m 167ms/step - accuracy: 0.4713 - loss: 6.5998[1m  31/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:11[0m 167ms/step - accuracy: 0.4735 - loss: 6.5589[1m  32/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:08[0m 167ms/step - accuracy: 0.4756 - loss: 6.5186[1m  33/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:07[0m 166ms/step - accuracy: 0.4775 - loss: 6.4795[1m  34/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:07[0m 167ms/step - accuracy: 0.4793 - loss: 6.4411[1m  35/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:04[0m 166ms/step - accuracy: 0.4811 - loss: 6.4028[1m  36/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:02[0m 166ms/step - accuracy: 0.4829 - loss: 6.3655[1m  37/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:02[0m 166ms/step - accuracy: 0.4845 - loss: 6.3291[1m  38/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:02[0m 166ms/step - accuracy: 0.4860 - loss: 6.2937[1m  39/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:05[0m 166ms/step - accuracy: 0.4875 - loss: 6.2589[1m  40/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:06[0m 166ms/step - accuracy: 0.4888 - loss: 6.2250[1m  41/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:11[0m 167ms/step - accuracy: 0.4901 - loss: 6.1920[1m  42/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:12[0m 167ms/step - accuracy: 0.4914 - loss: 6.1599[1m  43/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:12[0m 168ms/step - accuracy: 0.4926 - loss: 6.1285[1m  44/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:12[0m 167ms/step - accuracy: 0.4937 - loss: 6.0980[1m  45/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:11[0m 167ms/step - accuracy: 0.4948 - loss: 6.0678[1m  46/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:09[0m 167ms/step - accuracy: 0.4959 - loss: 6.0380[1m  47/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:08[0m 167ms/step - accuracy: 0.4971 - loss: 6.0085[1m  48/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:09[0m 167ms/step - accuracy: 0.4982 - loss: 5.9798[1m  49/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:08[0m 167ms/step - accuracy: 0.4992 - loss: 5.9517[1m  50/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:07[0m 167ms/step - accuracy: 0.5002 - loss: 5.9242[1m  51/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:04[0m 166ms/step - accuracy: 0.5012 - loss: 5.8973[1m  52/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:03[0m 166ms/step - accuracy: 0.5022 - loss: 5.8709[1m  53/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:05[0m 167ms/step - accuracy: 0.5031 - loss: 5.8450[1m  54/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:03[0m 166ms/step - accuracy: 0.5040 - loss: 5.8198[1m  55/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:01[0m 166ms/step - accuracy: 0.5049 - loss: 5.7951[1m  56/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:00[0m 166ms/step - accuracy: 0.5058 - loss: 5.7706[1m  57/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:04[0m 167ms/step - accuracy: 0.5067 - loss: 5.7467[1m  58/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:05[0m 167ms/step - accuracy: 0.5075 - loss: 5.7233[1m  59/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:02[0m 166ms/step - accuracy: 0.5083 - loss: 5.7003[1m  60/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m19:01[0m 166ms/step - accuracy: 0.5091 - loss: 5.6779[1m  61/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:59[0m 166ms/step - accuracy: 0.5098 - loss: 5.6559[1m  62/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:57[0m 166ms/step - accuracy: 0.5106 - loss: 5.6343[1m  63/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:55[0m 165ms/step - accuracy: 0.5113 - loss: 5.6132[1m  64/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:56[0m 166ms/step - accuracy: 0.5120 - loss: 5.5925[1m  65/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:57[0m 166ms/step - accuracy: 0.5127 - loss: 5.5722[1m  66/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:56[0m 166ms/step - accuracy: 0.5133 - loss: 5.5522[1m  67/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:55[0m 166ms/step - accuracy: 0.5140 - loss: 5.5326[1m  68/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:54[0m 165ms/step - accuracy: 0.5146 - loss: 5.5133[1m  69/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:54[0m 165ms/step - accuracy: 0.5153 - loss: 5.4943[1m  70/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:54[0m 165ms/step - accuracy: 0.5159 - loss: 5.4756[1m  71/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:53[0m 165ms/step - accuracy: 0.5166 - loss: 5.4572[1m  72/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:52[0m 165ms/step - accuracy: 0.5172 - loss: 5.4391[1m  73/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:51[0m 165ms/step - accuracy: 0.5178 - loss: 5.4214[1m  74/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:50[0m 165ms/step - accuracy: 0.5184 - loss: 5.4041[1m  75/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:49[0m 165ms/step - accuracy: 0.5189 - loss: 5.3870[1m  76/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:49[0m 165ms/step - accuracy: 0.5195 - loss: 5.3702[1m  77/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:48[0m 165ms/step - accuracy: 0.5201 - loss: 5.3536[1m  78/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:47[0m 165ms/step - accuracy: 0.5206 - loss: 5.3373[1m  79/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:46[0m 165ms/step - accuracy: 0.5211 - loss: 5.3214[1m  80/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:46[0m 165ms/step - accuracy: 0.5217 - loss: 5.3056[1m  81/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:46[0m 165ms/step - accuracy: 0.5222 - loss: 5.2901[1m  82/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:46[0m 165ms/step - accuracy: 0.5227 - loss: 5.2749[1m  83/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:45[0m 164ms/step - accuracy: 0.5232 - loss: 5.2601[1m  84/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:44[0m 164ms/step - accuracy: 0.5236 - loss: 5.2454[1m  85/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:43[0m 164ms/step - accuracy: 0.5241 - loss: 5.2311[1m  86/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:44[0m 164ms/step - accuracy: 0.5245 - loss: 5.2169[1m  87/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:42[0m 164ms/step - accuracy: 0.5250 - loss: 5.2029[1m  88/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:41[0m 164ms/step - accuracy: 0.5254 - loss: 5.1892[1m  89/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:41[0m 164ms/step - accuracy: 0.5259 - loss: 5.1756[1m  90/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:40[0m 164ms/step - accuracy: 0.5263 - loss: 5.1622[1m  91/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:39[0m 164ms/step - accuracy: 0.5267 - loss: 5.1491[1m  92/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:38[0m 164ms/step - accuracy: 0.5271 - loss: 5.1362[1m  93/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:38[0m 164ms/step - accuracy: 0.5275 - loss: 5.1235[1m  94/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:38[0m 164ms/step - accuracy: 0.5279 - loss: 5.1111[1m  95/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:37[0m 164ms/step - accuracy: 0.5282 - loss: 5.0988[1m  96/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:36[0m 163ms/step - accuracy: 0.5286 - loss: 5.0867[1m  97/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:35[0m 163ms/step - accuracy: 0.5290 - loss: 5.0748[1m  98/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:34[0m 163ms/step - accuracy: 0.5293 - loss: 5.0631[1m  99/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:34[0m 163ms/step - accuracy: 0.5296 - loss: 5.0516[1m 100/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:35[0m 163ms/step - accuracy: 0.5300 - loss: 5.0402[1m 101/6926[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18:35[0m 163ms/step - accuracy: 0.5303 - loss: 5.0290[2025-03-14 15:50:02 +0000] [8163] [CRITICAL] WORKER TIMEOUT (pid:8164)
[2025-03-14 15:50:02 +0000] [8164] [ERROR] Error handling request /train_tensor?n=10
Traceback (most recent call last):
  File "/home/ec2-user/nlp-py-backend/prodvnv/lib64/python3.9/site-packages/gunicorn/workers/sync.py", line 134, in handle
    self.handle_request(listener, req, client, addr)
  File "/home/ec2-user/nlp-py-backend/prodvnv/lib64/python3.9/site-packages/gunicorn/workers/sync.py", line 177, in handle_request
    respiter = self.wsgi(environ, resp.start_response)
  File "/home/ec2-user/nlp-py-backend/prodvnv/lib64/python3.9/site-packages/flask/app.py", line 1536, in __call__
    return self.wsgi_app(environ, start_response)
  File "/home/ec2-user/nlp-py-backend/prodvnv/lib64/python3.9/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/ec2-user/nlp-py-backend/prodvnv/lib64/python3.9/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/ec2-user/nlp-py-backend/prodvnv/lib64/python3.9/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "/home/ec2-user/nlp-py-backend/app/main.py", line 89, in trainTensorFunction
    result = self.train_tensor.createModel(epochs)
  File "/home/ec2-user/nlp-py-backend/app/trainers/training_tensorflow.py", line 241, in createModel
    t_history = self.trainTransformer(n)
  File "/home/ec2-user/nlp-py-backend/app/trainers/training_tensorflow.py", line 194, in trainTransformer
    history = self.transformer_model.fit(
  File "/home/ec2-user/nlp-py-backend/prodvnv/lib64/python3.9/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
    return fn(*args, **kwargs)
  File "/home/ec2-user/nlp-py-backend/prodvnv/lib64/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py", line 371, in fit
    logs = self.train_function(iterator)
  File "/home/ec2-user/nlp-py-backend/prodvnv/lib64/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py", line 219, in function
    opt_outputs = multi_step_on_iterator(iterator)
  File "/home/ec2-user/nlp-py-backend/prodvnv/lib64/python3.9/site-packages/tensorflow/python/util/traceback_utils.py", line 150, in error_handler
    return fn(*args, **kwargs)
  File "/home/ec2-user/nlp-py-backend/prodvnv/lib64/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py", line 833, in __call__
    result = self._call(*args, **kwds)
  File "/home/ec2-user/nlp-py-backend/prodvnv/lib64/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py", line 878, in _call
    results = tracing_compilation.call_function(
  File "/home/ec2-user/nlp-py-backend/prodvnv/lib64/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py", line 139, in call_function
    return function._call_flat(  # pylint: disable=protected-access
  File "/home/ec2-user/nlp-py-backend/prodvnv/lib64/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py", line 1322, in _call_flat
    return self._inference_function.call_preflattened(args)
  File "/home/ec2-user/nlp-py-backend/prodvnv/lib64/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py", line 216, in call_preflattened
    flat_outputs = self.call_flat(*args)
  File "/home/ec2-user/nlp-py-backend/prodvnv/lib64/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py", line 251, in call_flat
    outputs = self._bound_context.call_function(
  File "/home/ec2-user/nlp-py-backend/prodvnv/lib64/python3.9/site-packages/tensorflow/python/eager/context.py", line 1683, in call_function
    outputs = execute.execute(
  File "/home/ec2-user/nlp-py-backend/prodvnv/lib64/python3.9/site-packages/tensorflow/python/eager/execute.py", line 53, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
  File "/home/ec2-user/nlp-py-backend/prodvnv/lib64/python3.9/site-packages/gunicorn/workers/base.py", line 204, in handle_abort
    sys.exit(1)
SystemExit: 1
[2025-03-14 15:50:02 +0000] [8164] [INFO] Worker exiting (pid: 8164)
[2025-03-14 15:50:03 +0000] [8477] [INFO] Booting worker with pid: 8477
2025-03-14 15:50:04.062030: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2025-03-14 15:50:04.065449: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2025-03-14 15:50:04.076676: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741967404.096564    8477 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741967404.102412    8477 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-03-14 15:50:04.121816: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
2025-03-14 15:50:06,906 - INFO - Loading trained models...
2025-03-14 15:50:06.912440: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
2025-03-14 15:50:07,204 - INFO - Intent model loaded successfully..<class 'keras.src.models.sequential.Sequential'>
2025-03-14 15:50:07,431 - INFO - Transfomer model loaded successfully..<class 'keras.src.models.functional.Functional'>
2025-03-14 15:50:07,431 - INFO - Loading tokenizers...
2025-03-14 15:50:07,432 - INFO - Intent tokenizer loaded successfully.
2025-03-14 15:50:07,589 - INFO - Transformer tokenizer loaded successfully
2025-03-14 15:50:07,589 - INFO - Loading Label Encoder...
2025-03-14 15:50:07,590 - INFO - Label Encoder loaded successfully.
2025-03-14 15:50:07,590 - INFO - Loading max sequence length...
2025-03-14 15:50:07,590 - INFO - Max sequence length: 7
2025-03-14 15:50:07,590 - INFO - Loading responses...
2025-03-14 15:50:07,590 - INFO - Responses loaded successfully.
2025-03-14 15:50:07,712 - INFO - Loading intent data...
2025-03-14 15:50:07,712 - INFO - Loading complete.
2025-03-14 15:50:07,714 - INFO - Running in production...
